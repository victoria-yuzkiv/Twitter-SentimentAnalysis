{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about the dataset can be found here - http://help.sentiment140.com/for-students/ .\n",
    "<br/>Tweets are labelled either positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a CSV with emoticons removed. Data file format has 6 fields:\n",
    "\n",
    "0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "<br/>1 - the id of the tweet (2087)\n",
    "<br/>2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "<br/>3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "<br/>4 - the user that tweeted (robotickilldozr)\n",
    "<br/>5 - the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sentiment','id','date','query_string','user','text']\n",
    "df = pd.read_csv(\"data/training.1600000.processed.noemoticon.csv\",header=None, names=columns, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date query_string  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009     NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009     NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009     NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, 50% of the data has negative labels, and another 50% - positive ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make using of the dataset more convenient I will remove unnecessary columns and change the value for positive labels to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['id','date','query_string','user'],axis=1,inplace=True)\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>I just re-pierced my ears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>@octolinz16 It it counts, idk why I did either...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>@smarrison i would've been the first, but i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>@iamjazzyfizzle I wish I got to watch it with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>Hollis' death scene will hurt me severely to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>about to file taxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>@LettyA ahh ive always wanted to see rent  lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>@FakerPattyPattz Oh dear. Were you drinking ou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                               text\n",
       "0           0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1           0  is upset that he can't update his Facebook by ...\n",
       "2           0  @Kenichan I dived many times for the ball. Man...\n",
       "3           0    my whole body feels itchy and like its on fire \n",
       "4           0  @nationwideclass no, it's not behaving at all....\n",
       "5           0                      @Kwesidei not the whole crew \n",
       "6           0                                        Need a hug \n",
       "7           0  @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "8           0               @Tatiana_K nope they didn't have it \n",
       "9           0                          @twittera que me muera ? \n",
       "10          0        spring break in plain city... it's snowing \n",
       "11          0                         I just re-pierced my ears \n",
       "12          0  @caregiving I couldn't bear to watch it.  And ...\n",
       "13          0  @octolinz16 It it counts, idk why I did either...\n",
       "14          0  @smarrison i would've been the first, but i di...\n",
       "15          0  @iamjazzyfizzle I wish I got to watch it with ...\n",
       "16          0  Hollis' death scene will hurt me severely to w...\n",
       "17          0                               about to file taxes \n",
       "18          0  @LettyA ahh ive always wanted to see rent  lov...\n",
       "19          0  @FakerPattyPattz Oh dear. Were you drinking ou..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: HTML decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pears &amp; Brie, bottle of Cabernet, and &quot;Win a Date With Tad Hamilton&quot;... oh gawwd my life flashed forward to when I'm 40 with my 75 cats \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = df.text[492]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pears & Brie, bottle of Cabernet, and \"Win a Date With Tad Hamilton\"... oh gawwd my life flashed forward to when I'm 40 with my 75 cats \n"
     ]
    }
   ],
   "source": [
    "example1 = BeautifulSoup(tweet, 'html.parser')\n",
    "print(example1.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: dealing with @mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks? '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = df.text[19]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Oh dear. Were you drinking out of the forgotten table drinks? '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'@[A-Za-z0-9]+', '', tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: dealing with URL links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = df.text[0]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot  - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('https?://[A-Za-z0-9./]+', '', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('www.[^ ]+','', tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: UTF-8 BOM (Byte Order Mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tuesdayï¿½ll start with reflection ï¿½n then a lecture in Stress reducing techniques. That sure might become very useful for us accompaniers '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = df.text[226]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tuesday�ll start with reflection �n then a lecture in Stress reducing techniques. That sure might become very useful for us accompaniers '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = bytes(tweet,'iso-8859-1').decode('utf-8-sig')\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tuesday?ll start with reflection ?n then a lecture in Stress reducing techniques. That sure might become very useful for us accompaniers '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.replace(\"\\ufffd\", \"?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: hashtag / numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@machineplay I'm so sorry you're having to go through this. Again.  #therapyfail\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = df.text[175]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' machineplay I m so sorry you re having to go through this  Again    therapyfail'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[^a-zA-Z]\", \" \", tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll put all these methods in one function on order to apply it to the whole dataset. Moreover, I created the class that allows to perform all these operations (you can find it in tweet_preprocessing.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the updated datacleaning function. Changes with data:\n",
    "\n",
    "- HTML decoding\n",
    "\n",
    "- Dealing with @mention\n",
    "\n",
    "- Dealing with URL links\n",
    "\n",
    "- BOM removing\n",
    "\n",
    "- Removing non-numeric values\n",
    "\n",
    "- Casting to lower-case\n",
    "\n",
    "- Negation handling\n",
    "\n",
    "- Tokenizing and joining\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "negations = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations.keys()) + r')\\b')\n",
    "\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    bs = BeautifulSoup(tweet, 'html.parser')\n",
    "    bs_tweet = bs.get_text()\n",
    "    \n",
    "    try:\n",
    "        bom_tweet = bs_tweet.bytes(tweet,'iso-8859-1').decode('utf-8-sig').replace(\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_tweet = bs_tweet\n",
    "        \n",
    "    tweet = re.sub('@[A-Za-z0-9]+', '', bom_tweet)\n",
    "    tweet = re.sub('((www.[^ ]+)|(https?://[A-Za-z0-9./]+))','', tweet)\n",
    "    tweet_lowercase = tweet.lower()\n",
    "    without_negations = neg_pattern.sub(lambda x: negations[x.group()], tweet_lowercase)\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", \" \", without_negations)\n",
    "    # During the letters_only process few lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    return (\" \".join([x for x  in tok.tokenize(tweet) if len(x) > 1])).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 100000 of 1600000 has been processed\n",
      "Tweets 200000 of 1600000 has been processed\n",
      "Tweets 300000 of 1600000 has been processed\n",
      "Tweets 400000 of 1600000 has been processed\n",
      "Tweets 500000 of 1600000 has been processed\n",
      "Tweets 600000 of 1600000 has been processed\n",
      "Tweets 700000 of 1600000 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\victoriayuzkiv\\myenv\\lib\\site-packages\\bs4\\__init__.py:272: UserWarning: \"b' i just received my G8 viola exam.. and its... well... .. disappointing.. :\\\\..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 800000 of 1600000 has been processed\n",
      "Tweets 900000 of 1600000 has been processed\n",
      "Tweets 1000000 of 1600000 has been processed\n",
      "Tweets 1100000 of 1600000 has been processed\n",
      "Tweets 1200000 of 1600000 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\victoriayuzkiv\\myenv\\lib\\site-packages\\bs4\\__init__.py:272: UserWarning: \"b'E3 ON PLAYSTATION HOME IN ABOUT AN HOUR!!!!!!!!!! \\\\../  \\\\../'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 1300000 of 1600000 has been processed\n",
      "Tweets 1400000 of 1600000 has been processed\n",
      "Tweets 1500000 of 1600000 has been processed\n",
      "Tweets 1600000 of 1600000 has been processed\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "cleaned_tweets = []\n",
    "for i in range(df.shape[0]):\n",
    "    if (i+1)%100000 == 0:\n",
    "        print(\"Tweets {} of {} has been processed\".format(i+1, df.shape[0]))                                                                  \n",
    "    cleaned_tweets.append(clean_tweet(df['text'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(cleaned_tweets,columns=['text'])\n",
    "new_df['sentiment'] = df.sentiment\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596522, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df[new_df.text != '']\n",
    "new_df.reset_index(drop=True,inplace=True)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('cleaned_data.csv',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
